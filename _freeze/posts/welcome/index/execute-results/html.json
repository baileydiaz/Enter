{
  "hash": "4432bfaed8d98c7f3ceb8880bf43bf86",
  "result": {
    "markdown": "---\ntitle: \"BYUI Education Project\"\nauthor: \"Bailey Diaz\"\ndate: \"2024-05-29\"\ncategories: [news]\n---\n\n\n\n\nFor the past few weeks I have been working with Benjamin Pacini on his doctoral dissertation.  His topic of interest is, what makes a good teacher?  \n\nTo start off, I decided to create a model that predicts Danielson scores based off of Disposition scores.  Danielson scores are the scores that evaluators give student teachers.  They evaluate how well they do at controlling the classroom, teaching ability, and so fourth.  \n\nWhat we are using to predict Danielson scores are called dispositions.  Dispositions are scores that professors give their students.  These are essentially judgements calls and ask questions such as, \"Does this person seem to enjoy being with children?\"\n\nSo, my initial analysis investigated the following train of thought, do these judgement calls (dispositions) seem to have a relation to the actual student teacher evaluations? \n\nTo clarify, the dispositions are done when the student teacher is not present.  \n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## Danielson Predictor\n\nThese are the results of a very simple regression and the r-squared does not imply that we have strong correlation.  However, in social sciences we do not expect to see very high r-squared values.  In all honesty, this r-squared is higher than any other regression that we have tried.  \n\n\n::: {.cell}\n::: {.cell-output-display}\n----------------------------------------------------------------------------\n            &nbsp;               Estimate   Std. Error   t value   Pr(>|t|) \n------------------------------- ---------- ------------ --------- ----------\n        **(Intercept)**          -0.01393    0.02847     -0.4892    0.6248  \n\n **Disposition_highest_level**    0.4462     0.03016      14.8     1.15e-44 \n----------------------------------------------------------------------------\n\n\n--------------------------------------------------------------\n Observations   Residual Std. Error   $R^2$    Adjusted $R^2$ \n-------------- --------------------- -------- ----------------\n     938              0.8717          0.1895       0.1887     \n--------------------------------------------------------------\n\nTable: Fitting linear model: Danielson_492 ~ Disposition_highest_level\n:::\n:::\n\n\n\n# Future Endeavors\n\n## Robust Standard Errors\nThe chair for Brother Pacini's research has mentioned the importance of residual standard errors. I need to investigate the importance of this metric and see how it can apply to our research. \n\n::: {.cell}\n::: {.cell-output-display}\n* _-0.01393_\n  * _0.4462_\n  * _0.02863_\n  * _0.04713_\n  * _-0.4865_\n  * _9.466_\n  * _0.6268_\n  * _2.285e-20_\n\n<!-- end of list -->\n:::\n:::\n\n\n\n## Graph\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n              (Intercept) Disposition_highest_level \n              -0.01392646                0.44617503 \n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n#!!!!!!\n\n## Checking Requirements\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}